{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d77905",
   "metadata": {},
   "source": [
    "# Quickstart Guide: **Isolating Path Effect for Latent Circuit Discovery**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615e747",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4657c",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "The code in this repository is compatible with models from transformer-lens which is built on top of PyTorch. You can install it via pip:\n",
    "```bash\n",
    "pip install transformer-lens\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e51c3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device, torch_dtype=torch.float32, center_unembed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f5d45",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The current implementations are aimed at finding the circuit responsible for single token predictions. It may be adapted to other cases with appropriate changes but this is not currently supported out of the box.\n",
    "\n",
    "Furthermore if you want to perform a positional analysis, higlighting the contributions of single residual positions, you will need to provide batches with constant number of tokens. This is required because of the underlying assumption that throughout the batch, the meaning of the token at a certain position is similar. On the other hand, if you want to perform a non-positional analysis, you can use batches with variable number of tokens.\n",
    "\n",
    "In the below example we will use a small batch of 4 samples from the `mib-bench/ioi` dataset. This dataset is based on the Indirect Object Identification task [(K. Wang et al)](https://arxiv.org/abs/2211.00593), which is a common benchmark for mechanistic interpretability. You can find more information about the dataset [here](https://huggingface.co/datasets/mib-bench/ioi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f61396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example prompt:\n",
      "   `` Once Austin and Phil arrived at the ramp, Austin gave a backpack to ``\n",
      "  Answer: `` _Phil ``\n",
      "\n",
      "Counterfactual prompt:\n",
      "   `` Once Austin and Phil arrived at the ramp, Phil gave a backpack to ``\n",
      "  Counterfactual answer: `` _Austin ``\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mib-bench/ioi\", split=\"test\")\n",
    "batch_size = 4\n",
    "target_length = 15\n",
    "\n",
    "prompts, answers = [], []\n",
    "counterfactual_prompts, counterfactual_answers = [], []\n",
    "\n",
    "for sample in dataset:\n",
    "\tif model.to_tokens(sample['prompt'], prepend_bos=True).shape[1] == target_length:\n",
    "\t\tprompts.append(sample['prompt'])\n",
    "\t\tanswers.append(f' {sample['metadata']['indirect_object']}')\n",
    "\n",
    "\t\tcounterfactual_prompts.append(sample['s2_io_flip_counterfactual']['prompt'])\n",
    "\t\tcounterfactual_answers.append(f' {sample['s2_io_flip_counterfactual']['choices'][sample['s2_io_flip_counterfactual']['answerKey']]}')\n",
    "\t\tif len(prompts) >= batch_size:\n",
    "\t\t\tbreak\n",
    "\n",
    "print(\"Example prompt:\\n   ``\", prompts[0], \"``\")\n",
    "print(\"  Answer: ``\", answers[0].replace(' ', '_'), \"``\")\n",
    "\n",
    "print(\"\\nCounterfactual prompt:\\n   ``\", counterfactual_prompts[0], \"``\")\n",
    "print(\"  Counterfactual answer: ``\", counterfactual_answers[0].replace(' ', '_'), \"``\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84caea5",
   "metadata": {},
   "source": [
    "### Cache\n",
    "\n",
    "The main reason why we use transformer-lens is that it provides a caching mechanism that allows us to store the activations of the model during a forward pass. This is useful because we will need to access these activations multiple times during the path attribution patching process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13af47eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits, clean_cache = model.run_with_cache(model.to_tokens(prompts, prepend_bos=True))\n",
    "clean_probabilities = clean_logits.softmax(dim=-1)\n",
    "correct_token_ids = [model.to_single_token(answers[i]) for i in range(len(answers))]\n",
    "\n",
    "cf_logits, cf_cache = model.run_with_cache(model.to_tokens(counterfactual_prompts, prepend_bos=True))\n",
    "cf_probabilities = cf_logits.softmax(dim=-1)\n",
    "cf_token_ids = [model.to_single_token(counterfactual_answers[i]) for i in range(len(counterfactual_answers))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129102f1",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "The goal of this library is to identify circuits by isolating highly contributional paths. Obviously we need a way to measure the contribution of a path to the final prediction. This is done via metrics.\n",
    "We provide different metrics out of the box, but you can also define your own metric. The only requirement is that the metric can be expressed as a function of the corrupted final residual stream obtained after path patching.\n",
    "\n",
    "Here we provide two examples of metrics, a simple percentage of logit difference of the target token and the indirect effect metric [(A. Stolfo et al)](arxiv.org/abs/2305.15054).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "919194ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backward_search_approximated.utils.metrics import indirect_effect, compare_token_logit\n",
    "from functools import partial \n",
    "\n",
    "compare_token_logit_metric = partial(compare_token_logit, clean_resid=clean_cache[f'blocks.{model.cfg.n_layers-1}.hook_resid_post'], model=model, target_tokens=correct_token_ids)\n",
    "indirect_effect_metric = partial(indirect_effect, clean_resid=clean_cache[f'blocks.{model.cfg.n_layers-1}.hook_resid_post'], model=model, clean_targets=correct_token_ids, corrupt_targets=cf_token_ids, verbose=False, set_baseline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f72782",
   "metadata": {},
   "source": [
    "### Nodes\n",
    "\n",
    "Nodes are the building blocks of paths and are the core of our code. A node represents a specific component of the model at a specific layer and position (if applicable).\n",
    "\n",
    "Currently we support the following nodes:\n",
    "- `EMBED_Node`: the token embedding at position 0\n",
    "- `MLP_Node`: the MLP at a specific layer and position\n",
    "- `ATT_Node`: the attention head or block at a specific layer and position\n",
    "- `FINAL_Node`: a dummy node representing the final residual stream before the unembedding layer\n",
    "\n",
    "They expose three main methods:\n",
    "- `forward`: computes the output of the node when applying a given patching\n",
    "- `get_expansion_candidates`: returns all the predecessor nodes of the current node\n",
    "- `calculate_gradient`: computes the gradient of the metric with respect to the input of the node, passing through the path leading to the output\n",
    "\n",
    "\n",
    "Particularly to perform a search we have to start from the `FINAL_Node`, whose initialization will impact the behavior of the search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d662135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backward_search_approximated.utils.nodes import FINAL_ApproxNode\n",
    "\n",
    "root_node = FINAL_ApproxNode(\n",
    "\t\t\t\t\t\t\tmodel=model,\n",
    "\t\t\t\t\t\t\tlayer=model.cfg.n_layers - 1,\n",
    "\t\t\t\t\t\t\tmetric=indirect_effect_metric,\n",
    "\t\t\t\t\t\t\tposition=target_length - 1, #   <-- if None (non-positional analysis), else the last position of the sequence\n",
    "\t\t\t\t\t\t\tparent=None,\n",
    "\t\t\t\t\t\t\tchildren=set(),\n",
    "\t\t\t\t\t\t\tmsg_cache=dict(clean_cache),\n",
    "\t\t\t\t\t\t\tcf_cache=dict(cf_cache),\n",
    "\t\t\t\t\t\t\tgradient=None,\n",
    "\t\t\t\t\t\t\tpatch_type='counterfactual' # \t<--\teither 'zero' or 'counterfactual'\n",
    "\t\t\t\t\t\t\t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71d837b",
   "metadata": {},
   "source": [
    "## Backward Breadth-First Search (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ceee36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Starting node has no position defined. Batch positions will not be used.\n",
      "(total 1)    Frontier: [(tensor(4921.8726, grad_fn=<MeanBackward0>), [FINAL_ApproxNode(layer=11)])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(total 4)    Frontier: [(tensor(38.2632, grad_fn=<MeanBackward0>), [ATTN_ApproxNode(layer=9, head=9, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), FINAL_ApproxNode(layer=11)]), (tensor(38.2632, grad_fn=<MeanBackward0>), [ATTN_ApproxNode(layer=9, head=9, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)])]... ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:16<00:00,  4.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(total 4)    Frontier: [(tensor(6.8362, grad_fn=<MeanBackward0>), [ATTN_ApproxNode(layer=8, head=6, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=9, head=9, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(6.8362, grad_fn=<MeanBackward0>), [ATTN_ApproxNode(layer=8, head=6, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=9, head=9, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)])]... ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(total 2)    Frontier: [(tensor(2.2764, grad_fn=<MeanBackward0>), [ATTN_ApproxNode(layer=5, head=5, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=8, head=6, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=9, head=9, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(2.2764, grad_fn=<MeanBackward0>), [ATTN_ApproxNode(layer=5, head=5, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=8, head=6, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=9, head=9, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from backward_search_approximated.utils.graph_search import IsolatingPathEffect_BW\n",
    "\n",
    "minimum_contribution_threshold = 2\n",
    "\n",
    "indirect_effect_paths_BW = IsolatingPathEffect_BW(\n",
    "\tmodel=model,\n",
    "\tmetric=indirect_effect_metric, # You can change this to any metric you want (es. compare_token_logit_metric)\n",
    "\troot=root_node, # The root node of the search, if root.position is None the analysis will be non-positional\n",
    "\tmin_contribution=minimum_contribution_threshold, \n",
    "\tinclude_negative=True,\n",
    "\treturn_all=False,\n",
    "\tbatch_heads=True, # If True is faster but less precise (Note: if you have to chose generally batching heads is worse than batching positions)\n",
    "\tbatch_positions=True, # If True is faster but less precise (only for positional analysis)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126b823",
   "metadata": {},
   "source": [
    "## Path Attribution Patching (PAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "655a2ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.58s/it]\n",
      "100%|██████████| 39/39 [00:10<00:00,  3.61it/s]\n",
      "100%|██████████| 73/73 [00:22<00:00,  3.30it/s]\n",
      "100%|██████████| 33/33 [00:06<00:00,  4.89it/s]\n",
      "100%|██████████| 8/8 [00:01<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 paths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "100%|██████████| 27/27 [00:01<00:00, 14.50it/s]\n",
      "100%|██████████| 76/76 [00:04<00:00, 17.13it/s]\n",
      "100%|██████████| 33/33 [00:01<00:00, 21.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 paths\n"
     ]
    }
   ],
   "source": [
    "from backward_search_approximated.utils.graph_search import PathAttributionPatching\n",
    "\n",
    "minimum_contribution_threshold = 0.1\n",
    "\n",
    "indirect_effect_paths_PAP = PathAttributionPatching(\n",
    "\tmodel=model,\n",
    "\tmetric=indirect_effect_metric, # You can change this to any metric you want (es. compare_token_logit_metric)\n",
    "\troot=root_node, # The root node of the search, if root.position is None the analysis will be non-positional\n",
    "\tmin_contribution=minimum_contribution_threshold, \n",
    "\tinclude_negative=True,\n",
    "\treturn_all=False,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(indirect_effect_paths_PAP)} paths\")\n",
    "\n",
    "root_node.position = None\n",
    "indirect_effect_paths_PAP_nonpositional = PathAttributionPatching(\n",
    "\tmodel=model,\n",
    "\tmetric=indirect_effect_metric, # You can change this to any metric you want (es. compare_token_logit_metric)\n",
    "\troot=root_node, # The root node of the search, if root.position is None the analysis will be non-positional\n",
    "\tmin_contribution=minimum_contribution_threshold, \n",
    "\tinclude_negative=True,\n",
    "\treturn_all=False,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(indirect_effect_paths_PAP_nonpositional)} paths\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd825e4",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9707ef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backward Breadt-First Search Paths:\n",
      "[]\n",
      "\n",
      "Path Attribution Patching Search Paths:\n",
      "[(tensor(0.8353, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=10), MLP_ApproxNode(layer=0, position=10), ATTN_ApproxNode(layer=5, head=5, position=10, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(0.2592, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=10), MLP_ApproxNode(layer=0, position=10), ATTN_ApproxNode(layer=5, head=5, position=10, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=10, head=10, position=14, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(0.1682, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=10), MLP_ApproxNode(layer=0, position=10), ATTN_ApproxNode(layer=6, head=9, position=10, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=9, head=9, position=14, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(0.1060, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=10), MLP_ApproxNode(layer=0, position=10), ATTN_ApproxNode(layer=6, head=9, position=10, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=8, head=6, position=14, keyvalue_position=10, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=10, head=10, position=14, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(-0.0876, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=10), MLP_ApproxNode(layer=0, position=10), ATTN_ApproxNode(layer=11, head=2, position=14, keyvalue_position=10, patch_query=False, patch_key=True, patch_value=True), FINAL_ApproxNode(layer=11)])]\n",
      "\n",
      "Path Attribution Patching Search Paths (non positional):\n",
      "[(tensor(0.8376, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=None), MLP_ApproxNode(layer=0, position=None), ATTN_ApproxNode(layer=5, head=5, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=8, head=6, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=9, head=9, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(0.2591, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=None), MLP_ApproxNode(layer=0, position=None), ATTN_ApproxNode(layer=5, head=5, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=8, head=6, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=10, head=10, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(0.1692, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=None), MLP_ApproxNode(layer=0, position=None), ATTN_ApproxNode(layer=6, head=9, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=8, head=6, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=9, head=9, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(0.1059, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=None), MLP_ApproxNode(layer=0, position=None), ATTN_ApproxNode(layer=6, head=9, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), ATTN_ApproxNode(layer=8, head=6, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), ATTN_ApproxNode(layer=10, head=10, position=None, keyvalue_position=None, patch_query=True, patch_key=False, patch_value=False), FINAL_ApproxNode(layer=11)]), (tensor(-0.0804, grad_fn=<MeanBackward0>), [EMBED_ApproxNode(layer=0, position=None), MLP_ApproxNode(layer=0, position=None), ATTN_ApproxNode(layer=11, head=2, position=None, keyvalue_position=None, patch_query=False, patch_key=True, patch_value=True), FINAL_ApproxNode(layer=11)])]\n"
     ]
    }
   ],
   "source": [
    "print(\"Backward Breadt-First Search Paths:\")\n",
    "print(indirect_effect_paths_BW)\n",
    "\n",
    "print(\"\\nPath Attribution Patching Search Paths:\")\n",
    "print(indirect_effect_paths_PAP)\n",
    "\n",
    "print(\"\\nPath Attribution Patching Search Paths (non positional):\")\n",
    "print(indirect_effect_paths_PAP_nonpositional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
